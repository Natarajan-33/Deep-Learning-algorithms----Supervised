- In this project, the preprocessing part of donor choose dataset is done by appliedaicourse team members and my contribution is Building 3 different model with different featurization technique which is as follows
- In Model_1 tokenize the all text data to Encode,pad for vectorization. This is input to LSTM model. For the categorical features we OHE it and then pad it for using them later in embedding layer as a featurizing step to pass them into dense layer and then design rest of the architecture as mentioned in the ipython notebook
- In Model_2 tokenize the high idf valued text data to Encode,pad for vectorization. This is input to LSTM model. For the categorical features we OHE it and then pad it for using them later in embedding layer as a featurizing step to pass them into dense layer and then design rest of the architecture as mentioned in the ipython notebook
- In Model_3 tokenize the all text data to Encode,pad for vectorization.This is input to LSTM model. For the categorical features we use BOW representation and stacking all the categorical features to input into 1Dconv layer and then design rest of the architecture as mentioned in the ipython notebook
- Necessary Data can be downloaded from [here](https://drive.google.com/drive/folders/1DWqU-LVHm5hntP-BWk-m9xPZslWRVRUT?usp=share_link)
